{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KrituneX/Hands-on-Machine-Learning-with-Scikit-Learn-Keras-TensorFlow/blob/main/Chapter_12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "507a9eeb",
      "metadata": {
        "id": "507a9eeb"
      },
      "source": [
        "## Chapter 12: Model dan Pelatihan Kustom dengan TensorFlow\n",
        "Ringkasan berdasarkan *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow* oleh AurÃ©lien GÃ©ron."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86445a35",
      "metadata": {
        "id": "86445a35"
      },
      "source": [
        "### 1. TensorFlow Sebagai Alat Komputasi Numerik\n",
        "TensorFlow (TF) adalah framework komputasi numerik berbasis grafik. Objek dasar dalam TF adalah *tensor*.\n",
        "- Tensor adalah array multidimensi (mirip NumPy ndarray).\n",
        "- Operasi pada tensor dibangun sebagai grafik eksekusi yang dapat dijalankan di CPU, GPU, atau TPU.\n",
        "- TF menyediakan `tf.Variable`, `tf.constant`, dan `tf.function` untuk mendefinisikan operasi secara deklaratif.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "864d520a",
      "metadata": {
        "id": "864d520a"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Contoh Tensor dan Operasi\n",
        "a = tf.constant([[1., 2.], [3., 4.]])\n",
        "b = tf.constant([[1., 1.], [0., 1.]])\n",
        "c = tf.matmul(a, b)\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99c7700a",
      "metadata": {
        "id": "99c7700a"
      },
      "source": [
        "### 2. Membuat Fungsi Loss Kustom\n",
        "Fungsi loss mengukur seberapa baik model memprediksi output yang diharapkan.\n",
        "Contoh: Mean Squared Error (MSE):\n",
        "\n",
        "$$ \\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e619f180",
      "metadata": {
        "id": "e619f180"
      },
      "outputs": [],
      "source": [
        "# Contoh fungsi loss MSE kustom\n",
        "def my_mse(y_true, y_pred):\n",
        "    return tf.reduce_mean(tf.square(y_true - y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e3108a9",
      "metadata": {
        "id": "5e3108a9"
      },
      "source": [
        "### 3. Training Manual dengan GradientTape\n",
        "`tf.GradientTape()` memungkinkan perhitungan otomatis turunan (autodiff).\n",
        "Langkah-langkah manual training:\n",
        "1. Forward pass untuk menghitung loss\n",
        "2. Backward pass untuk menghitung gradien\n",
        "3. Update parameter model dengan optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "323317b3",
      "metadata": {
        "id": "323317b3"
      },
      "outputs": [],
      "source": [
        "# Contoh training loop manual\n",
        "X = tf.constant([[1.0], [2.0], [3.0], [4.0]])\n",
        "y = tf.constant([[2.0], [4.0], [6.0], [8.0]])\n",
        "\n",
        "model = tf.keras.Sequential([tf.keras.layers.Dense(1)])\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "\n",
        "for step in range(100):\n",
        "    with tf.GradientTape() as tape:\n",
        "        y_pred = model(X)\n",
        "        loss = tf.reduce_mean(tf.square(y - y_pred))\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcbda4e4",
      "metadata": {
        "id": "dcbda4e4"
      },
      "source": [
        "### 4. Model, Layer, dan Aktivasi Kustom\n",
        "- Kustomisasi layer dengan subclass `tf.keras.layers.Layer`\n",
        "- Model kustom dengan subclass `tf.keras.Model`\n",
        "- Gunakan metode `call()` untuk menentukan forward pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25248e4f",
      "metadata": {
        "id": "25248e4f"
      },
      "outputs": [],
      "source": [
        "# Layer kustom: layer Dense manual\n",
        "class MyDenseLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super().__init__()\n",
        "        self.units = units\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.w = self.add_weight(name=\"w\", shape=(input_shape[-1], self.units), initializer=\"random_normal\")\n",
        "        self.b = self.add_weight(name=\"b\", shape=(self.units,), initializer=\"zeros\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.matmul(inputs, self.w) + self.b"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3aff60b1",
      "metadata": {
        "id": "3aff60b1"
      },
      "source": [
        "### 5. Kustomisasi Fungsi Aktivasi, Regularisasi, dan Constraint\n",
        "- Contoh: fungsi aktivasi kustom ReLU dengan clipping\n",
        "\n",
        "$$ f(x) = \\min(\\max(0, x), 1) $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04cf5ff0",
      "metadata": {
        "id": "04cf5ff0"
      },
      "outputs": [],
      "source": [
        "# Aktivasi kustom\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def clipped_relu(x):\n",
        "    return tf.keras.activations.relu(x, max_value=1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c4349d7",
      "metadata": {
        "id": "1c4349d7"
      },
      "source": [
        "### ðŸ“Œ Kesimpulan\n",
        "Chapter ini memperkenalkan fleksibilitas penuh TensorFlow untuk:\n",
        "- Menghitung turunan dengan `GradientTape`\n",
        "- Membangun layer/model dari awal\n",
        "- Mengatur training loop secara manual\n",
        "- Membuat loss, aktivasi, dan constraint sendiri\n",
        "Sangat berguna untuk eksperimen dan riset Deep Learning."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}