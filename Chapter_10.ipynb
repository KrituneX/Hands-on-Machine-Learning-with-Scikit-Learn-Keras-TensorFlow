{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KrituneX/Hands-on-Machine-Learning-with-Scikit-Learn-Keras-TensorFlow/blob/main/Chapter_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZXdE7bEpL3I"
      },
      "source": [
        "# Chapter 10: Introduction to Artificial Neural Networks with Keras\n",
        "## Hands-On Machine Learning with Scikit-Learn, Keras and TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgk3LGqZpL3J"
      },
      "source": [
        "## 1. Fundamental Concepts of Neural Networks\n",
        "\n",
        "### 1.1 Biological Inspiration\n",
        "Jaringan saraf tiruan terinspirasi dari struktur otak biologis:\n",
        "- **Neuron**: Unit pemroses dasar (≈10^11 neuron di otak manusia)\n",
        "- **Dendrites**: Menerima sinyal input\n",
        "- **Axons**: Mengirim sinyal output\n",
        "- **Synapses**: Koneksi antar neuron (dapat diperkuat/diperlemah)\n",
        "\n",
        "### 1.2 Artificial Neuron (Perceptron)\n",
        "Model matematis neuron dengan:\n",
        "- Input: $x = [x_1, x_2, ..., x_n]$\n",
        "- Weights: $w = [w_1, w_2, ..., w_n]$\n",
        "- Bias: $b$\n",
        "- Activation function: $\\phi$\n",
        "\n",
        "**Output Calculation**:\n",
        "$$ z = w^T x + b $$\n",
        "$$ a = \\phi(z) $$\n",
        "\n",
        "### 1.3 Activation Functions\n",
        "Fungsi non-linear yang menentukan output neuron:\n",
        "\n",
        "| Fungsi | Formula | Range | Kelebihan |\n",
        "|--------|---------|-------|-----------|\n",
        "| Sigmoid | $\\sigma(z) = \\frac{1}{1+e^{-z}}$ | (0,1) | Output probabilistic |\n",
        "| Tanh | $tanh(z) = \\frac{e^z - e^{-z}}{e^z + e^{-z}}$ | (-1,1) | Zero-centered |\n",
        "| ReLU | $ReLU(z) = max(0,z)$ | [0,∞) | Tidak ada vanishing gradient |\n",
        "| Leaky ReLU | $LReLU(z) = max(\\alpha z,z)$ | (-∞,∞) | Memperbaiki dying ReLU |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyLEU4u-pL3K"
      },
      "source": [
        "## 2. Multi-Layer Perceptron (MLP) Architecture\n",
        "\n",
        "### 2.1 Layer Organization\n",
        "- **Input Layer**: Menerima data mentah (jumlah neuron = jumlah fitur)\n",
        "- **Hidden Layers**: 1+ lapisan tersembunyi (biasanya 1-5 layer)\n",
        "- **Output Layer**: Menghasilkan prediksi (jumlah neuron tergantung task)\n",
        "\n",
        "**Contoh Arsitektur** untuk klasifikasi 3 kelas:\n",
        "- Input: 4 features → 4 neurons\n",
        "- Hidden 1: 10 neurons (ReLU)\n",
        "- Hidden 2: 8 neurons (ReLU)\n",
        "- Output: 3 neurons (Softmax)\n",
        "\n",
        "### 2.2 Forward Propagation\n",
        "Proses perhitungan dari input ke output:\n",
        "$$ a^{[l]} = \\phi(W^{[l]T} a^{[l-1]} + b^{[l]}) $$\n",
        "\n",
        "### 2.3 Backpropagation Algorithm\n",
        "Proses pembelajaran dengan gradient descent:\n",
        "1. Hitung error di output layer:\n",
        "$$ \\delta^{[L]} = \\nabla_a J \\odot \\phi'(z^{[L]}) $$\n",
        "2. Propagasi error backward:\n",
        "$$ \\delta^{[l]} = (W^{[l+1]T} \\delta^{[l+1]}) \\odot \\phi'(z^{[l]}) $$\n",
        "3. Update weights dan biases:\n",
        "$$ W^{[l]} := W^{[l]} - \\eta \\delta^{[l]} a^{[l-1]T} $$\n",
        "$$ b^{[l]} := b^{[l]} - \\eta \\delta^{[l]} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-oLPv7gpL3K"
      },
      "source": [
        "## 3. Implementing Neural Networks with Keras\n",
        "\n",
        "### 3.1 Building an MLP for MNIST Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSevm_FTpL3K"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Preprocessing\n",
        "X_train = X_train.reshape(-1, 28*28) / 255.0\n",
        "X_test = X_test.reshape(-1, 28*28) / 255.0\n",
        "\n",
        "# Build model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=15,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)\n",
        "\n",
        "# Evaluate\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Am6hjD3ypL3L"
      },
      "source": [
        "### 3.2 Advanced Model Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFEajlhgpL3L"
      },
      "outputs": [],
      "source": [
        "# Plot training history\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f75tu5IrpL3L"
      },
      "source": [
        "## 4. Hyperparameter Tuning\n",
        "\n",
        "### 4.1 Optimizers Comparison\n",
        "- **SGD**: $ \\theta := \\theta - \\eta \\nabla_\\theta J(\\theta) $\n",
        "- **Momentum**: $ v := \\gamma v + \\eta \\nabla_\\theta J(\\theta) $\n",
        "              $ \\theta := \\theta - v $\n",
        "- **Adam**: Kombinasi Momentum + RMSProp\n",
        "\n",
        "### 4.2 Regularization Techniques\n",
        "- **L2 Regularization**: $ J(\\theta) = Loss + \\frac{\\lambda}{2}||\\theta||^2 $\n",
        "- **Dropout**: Random deactivation neurons selama training\n",
        "- **Early Stopping**: Menghentikan training ketika validasi error mulai naik"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgDFtBlrpL3L"
      },
      "source": [
        "## 5. Practical Implementation with Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2nW9Kk6pL3L"
      },
      "outputs": [],
      "source": [
        "# Advanced model with callbacks\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "\n",
        "def lr_scheduler(epoch, lr):\n",
        "    if epoch < 5:\n",
        "        return lr\n",
        "    else:\n",
        "        return lr * tf.math.exp(-0.1)\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=3, restore_best_weights=True),\n",
        "    ModelCheckpoint('best_model.h5', save_best_only=True),\n",
        "    LearningRateScheduler(lr_scheduler)\n",
        "]\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                   epochs=50,\n",
        "                   batch_size=64,\n",
        "                   validation_split=0.2,\n",
        "                   callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcVRr6NIpL3L"
      },
      "source": [
        "## 6. Model Evaluation and Interpretation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFBEx3k7pL3L"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred_classes)\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n",
        "\n",
        "# Misclassified examples\n",
        "misclassified_idx = np.where(y_pred_classes != y_test)[0]\n",
        "plt.figure(figsize=(15,4))\n",
        "for i, idx in enumerate(misclassified_idx[:5]):\n",
        "    plt.subplot(1,5,i+1)\n",
        "    plt.imshow(X_test[idx].reshape(28,28), cmap='gray')\n",
        "    plt.title(f'True: {y_test[idx]}\\nPred: {y_pred_classes[idx]}')\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Penjelasan Tambahan:**\n",
        "\n",
        "### **1. Teori Mendalam:**\n",
        "- Penjelasan biologi neuron dan analogi ke ANN\n",
        "- Detail matematis forward/backpropagation\n",
        "- Perbandingan berbagai activation functions dan optimizers\n",
        "- Persamaan matematis untuk semua komponen kunci"
      ],
      "metadata": {
        "id": "vGnmY69EpOxz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Implementasi Praktis:**\n",
        "- Contoh lengkap klasifikasi MNIST\n",
        "- Visualisasi training process\n",
        "- Implementasi callback untuk training canggih\n",
        "- Analisis hasil dengan confusion matrix"
      ],
      "metadata": {
        "id": "6-TF7vgEpcFU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. Best Practices:**\n",
        "- Teknik regularisasi (L2, Dropout)\n",
        "- Hyperparameter tuning\n",
        "- Early stopping\n",
        "- Learning rate scheduling"
      ],
      "metadata": {
        "id": "0kMvzHjOpdUM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. Model Evaluation:**\n",
        "- Interpretasi confusion matrix\n",
        "- Analisis misclassified examples\n",
        "- Visualisasi prediksi"
      ],
      "metadata": {
        "id": "y-YcbPAHprY0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5. Struktur Jelas:**\n",
        "- Pembagian section sistematis\n",
        "- Kode dan teori terintegrasi\n",
        "- Diagram dan visualisasi pendukung"
      ],
      "metadata": {
        "id": "Gr0h0aSupvQW"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}