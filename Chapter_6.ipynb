{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KrituneX/Hands-on-Machine-Learning-with-Scikit-Learn-Keras-TensorFlow/blob/main/Chapter_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxzWMJJpgeVO"
      },
      "source": [
        "# Chapter 6: Decision Trees\n",
        "\n",
        "## Ringkasan\n",
        "Pohon Keputusan adalah metode pembelajaran mesin yang membagi data secara hierarkis berdasarkan fitur untuk membuat prediksi. Model ini sangat populer karena kemudahan interpretasi dan implementasinya. Pohon keputusan dapat digunakan untuk tugas klasifikasi, di mana hasilnya adalah kategori, atau untuk regresi, di mana hasilnya adalah nilai kontinu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDEbWKmkgeVQ"
      },
      "source": [
        "## Konsep Utama\n",
        "\n",
        "1. **Komponen Utama**\n",
        "   - **Node Akar**: Titik awal dari pohon keputusan yang mewakili seluruh dataset.\n",
        "   - **Node Dalam**: Mewakili fitur yang digunakan untuk membagi data. Setiap node dalam pohon memiliki kondisi yang menentukan bagaimana data dibagi.\n",
        "   - **Daun**: Node akhir yang memberikan hasil prediksi. Setiap daun mewakili kelas (untuk klasifikasi) atau nilai (untuk regresi).\n",
        "\n",
        "2. **Algoritma CART (Classification and Regression Trees)**\n",
        "   - Algoritma ini digunakan oleh scikit-learn untuk membangun pohon keputusan. CART bekerja dengan cara mencari pembagian terbaik yang meminimalkan ketidakmurnian (impurity).\n",
        "   - **Pseudocode**:\n",
        "     1. Hitung impurity untuk semua fitur yang ada.\n",
        "     2. Pilih fitur dengan impurity terendah untuk melakukan pemisahan.\n",
        "     3. Bagi dataset menjadi subset berdasarkan pemisahan tersebut.\n",
        "     4. Ulangi proses ini secara rekursif hingga kriteria penghentian terpenuhi (misalnya, kedalaman maksimum atau jumlah minimum sampel di daun).\n",
        "\n",
        "3. **Ukuran Ketidakmurnian**\n",
        "   - Metrik untuk menilai kualitas pembagian dalam pohon keputusan. Dua ukuran yang umum digunakan adalah:\n",
        "     - **Indeks Gini**:\n",
        "       \\[ G = 1 - \\sum_{k=1}^{K} p_k^2 \\]\n",
        "       Di mana \\( p_k \\) adalah proporsi kelas \\( k \\) dalam node. Nilai Gini berkisar antara 0 (murni) hingga 0.5 (acak).\n",
        "     - **Entropi**:\n",
        "       \\[ H = -\\sum_{k=1}^{K} p_k \\log(p_k) \\]\n",
        "       Di mana \\( p_k \\) adalah proporsi kelas \\( k \\) dalam node. Entropi juga berkisar antara 0 (murni) hingga log(K) (acak).\n",
        "\n",
        "4. **Parameter Pengendali**\n",
        "   - Parameter yang digunakan untuk mencegah overfitting dan mengontrol kompleksitas pohon:\n",
        "     - `max_depth`: Menentukan kedalaman maksimum pohon. Semakin dalam pohon, semakin besar risiko overfitting.\n",
        "     - `min_samples_split`: Jumlah minimum sampel yang diperlukan untuk membagi node. Jika jumlah sampel kurang dari nilai ini, node tidak akan dibagi.\n",
        "     - `min_samples_leaf`: Jumlah minimum sampel yang harus ada di daun. Ini membantu memastikan bahwa setiap daun memiliki cukup data untuk membuat prediksi yang andal.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPUnnGGJgeVQ"
      },
      "outputs": [],
      "source": [
        "# Contoh Kode untuk Visualisasi Pohon Keputusan\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Membuat model pohon keputusan\n",
        "tree_clf = DecisionTreeClassifier(max_depth=2)\n",
        "tree_clf.fit(X, y)\n",
        "\n",
        "# Visualisasi pohon\n",
        "plt.figure(figsize=(12,8))\n",
        "plot_tree(tree_clf, filled=True)\n",
        "plt.title('Visualisasi Pohon Keputusan')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njUl9HD3geVR"
      },
      "outputs": [],
      "source": [
        "# Contoh Kode untuk Tuning Parameter\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Mencari parameter terbaik\n",
        "params = {\n",
        "  'max_depth': [3, 5, 7],\n",
        "  'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "grid_search = GridSearchCV(\n",
        "  DecisionTreeClassifier(),\n",
        "  params,\n",
        "  cv=5\n",
        ")\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Menampilkan parameter terbaik\n",
        "print(\"Parameter terbaik:\", grid_search.best_params_)\n",
        "print(\"Akurasi terbaik:\", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHR7bUIggeVR"
      },
      "source": [
        "## Catatan Penting\n",
        "- **Keunggulan**: Mudah diinterpretasi, tidak memerlukan penskalaan fitur, dan dapat menangani data kategorikal dan numerik.\n",
        "- **Kelemahan**: Rentan terhadap overfitting, terutama jika pohon terlalu dalam. Sensitif terhadap data noise dan outlier.\n",
        "- **Solusi**: Gunakan metode ensemble seperti Random Forest atau Gradient Boosting untuk meningkatkan stabilitas dan akurasi model."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}